한빛+ 데브그라운드 2025 with Upstage

컨퍼런스 개요
AI와 개발의 미래를 탐구하고, 실전 경험으로 풀어낸 개발자들의 사례를 통해 개발자 관점 노하우 공유.

세션 요약

1. 2030년에는 우리는 어떻게 일하고 있을까?
발표자: 박태웅 | 녹서포럼 의장
시간: 09:20 ~ 09:40
강의 내용:
- 기술과 AI 발전이 일과 조직 문화에 미칠 장기적 변화 전망
- 개발자의 역할은 “도구 활용 + 통합 역량”이 핵심

2. AI 시대 개발자가 반드시 알아야 할 속도 향상 비법
발표자: 하용호 | 데이터오븐 CEO
시간: 09:40 ~ 10:20
강의 내용:
- 개발 생산성을 극대화하는 AI 기반 툴과 워크플로우
- 테스트 자동화, 코드 리뷰 자동화, 반복 작업 효율화 강조

3. LLM, 믿고 쓸 수 있을까요? 지표 중심 LLM 모니터링
발표자: 송인서 | 업스테이지 SW엔지니어
시간: 10:20 ~ 11:00
## 강의 내용
### 1. LLM 운영의 어려움
- 고객 요구사항이 불명확한 경우가 많음 → 리소스 요구 파악이 까다로움  
- LLM은 토큰 단위로 응답 생성 → **비용과 성능이 가변적이고 예측이 어려움**  
- 따라서 **서비스를 먼저 운영**하고, 모니터링 지표를 기반으로 개선하는 접근이 필요  

### 2. LLM 추론 과정
- 입력(프롬프트) 처리 후 토큰 생성 시작  
- 출력은 토큰 단위로 순차 생성  
- 내부 계산 결과는 캐싱될 수 있음 (KV 캐시 등)  

### 3. 주요 모니터링 지표
- **TTFT (Time To First Token)**  
  - 첫 토큰이 나오기까지 걸리는 시간 = prefill + 1 token decode + network latency  
  - 입력 토큰 수에 비례  
  - 사용성에 큰 영향을 미침 → *낮을수록 좋음*  

- **ITL (Inter-Token Latency) / TPOT (Time Per Output Token)**  
  - 한 토큰을 생성하는 데 걸리는 시간  
  - 대화형 서비스에서 체감 속도와 직결 → *낮을수록 좋음*  

- **TPS (Tokens Per Second)**  
  - 초당 생성되는 토큰 수  
  - throughput을 직관적으로 표현 (ITL 역수)  
  - *높을수록 좋음*  

- **Latency (전체 요청 지연 시간)**  
  - 전체 처리 시간  
  - 토큰 수에 따라 가변적이므로 성능 지표로는 보조적 의미  
  - 모델/서비스 경향 파악에는 유용  

- **Input/Output Tokens**  
  - 요청 단위 워크로드 파악  
  - 비용 추정 및 과금 관리에 중요  

- **System Metrics**  
  - GPU, 메모리 등 시스템 자원 활용도 모니터링  

### 4. 기타 운영 팁
- 단일 지표로 모델 성능을 정의하기는 어렵다 → 지표를 종합적으로 해석 필요  
- 프롬프트 캐시 고려: 정적인 정보를 상단에 배치하면 효율적  
- 서비스 특성에 따라 어느 지표가 더 중요한지가 달라진다  

---

## 요약
- **속도 지표(TTFT, ITL)는 사용자 경험(UX)에 결정적 영향을 준다.**  
- 단순히 “LLM이 동작한다”에서 그치는 것이 아니라, **어떤 지표를 관리하느냐**가 성공적인 서비스 운영의 핵심.  
- 프롬프트 설계, 캐시 활용 같은 운영 노하우가 비용·성능 모두에 큰 차이를 만든다.  

4. 쉽게 시작해 보는 AI Agent 구현
발표자: 박찬성 | ETRI 연구원
시간: 11:10 ~ 11:50
## 강의 내용
- **AI Agentic System 개념**
  - 요구(고수준 인터페이스) → 지능적 처리(AI 모델) → 원하는 결과  
  - 핵심은 AI와 **도구(tools)의 연계**  
    - 도구 목적: ① 지식 습득 ② 행동 실행  
  - Context 관리 + 도구 호출 결과 활용이 중요  

- **구조적 패턴의 등장**
  - Routing workflow  
  - Evaluator–optimizer workflow (LLM as Judge)  

- **구현 관점**
  - LLM/VLM이 중심이지만, 블랙박스 특성 때문에 디버깅이 어렵다  
  - 유닛 테스트처럼 작은 단위 검증이 필요 → 바닐라 파이썬으로 단순 실험 추천  
  - 모든 결정을 도구 호출에만 의존하는 건 비현실적  
    - 맥락 관리/대화 히스토리 처리가 중요  

- **실전 고려사항**
  - LLM이 완벽히 의사결정을 대체하지 못함  
  - 복잡한 파이프라인 대신 **가능한 한 AI 자체로 문제를 해결하는 구조**를 추구해야 함  
  - AI 생태계 발전은 예측 불가능 → 유연한 접근 필요  

5. LLM 시대를 살아가는 인디 개발자의 AI 가제트 팔
발표자: 전미정 | 그리놀로지 CEO
시간: 12:50 ~ 13:30
## 강의 요약
- **인디 개발자 팀 구조**
  - John: 기획/디자인
  - Mijeong: 개발

- **주요 프로젝트: Blink 앱**
  - 빠른 메모 앱: 단어 단위 박스로 노출
  - 기능 단순화, 복잡한 기능 배포 최소화
  - 데이터는 사용자 앱 내 저장, Realm/iCloud 백업 가능하나 싱크 불가
  - 마이그레이션 고려: 데이터 손실 방지, 앱 종료, 대량 데이터 처리 문제

- **AI 도구 활용**
  - 앱 개발과 코드 작성에 다양한 AI 도구 사용
    - ChatGPT + Xcode
    - Claude Code 구독
    - Gemini + Codex CLI
    - Swift Assist (오류 및 원치 않는 수정 발생)
    - Codex CLI + Azure OpenAI (속도 및 토큰 확인 문제)
    - Cline (VSCode 기반, 단계별 세분화)
    - GitHub Copilot (유료 사용자 코드 리뷰 가능)
  - 단계별 마이그레이션 예시: Realm → Core Data
  - AI 도구 선택 기준:
    1. 데이터 보안
    2. 다양한 모델 연동 (Authorized Cloud)
    3. 명확한 단계 구분 (plan/act)
    4. 문맥 관리 용이
    5. 가능하면 오픈소스 활용

- **핵심 메시지**
  - 다양한 AI 툴이 존재하므로 상황에 맞게 선택해 **코딩 파트너**로 활용하는 것이 효과적
  - AI 도구는 완벽하지 않으므로, 직접 확인하고 검증하며 개발하는 습관 필요

6. 글로벌 시장에서 AI로 살아남기
발표자: 황인서 | 쿼리파이 Founder & CEO
시간: 13:40 ~ 14:20
## 강의 요약
- **일본 시장 특징**
  - 대기업 중심으로 AI 도입 → 비용 절감, 생산성 향상 목적  
  - 조직 구조 복잡, 데이터 보안 고려 → LLM 활용 허들 존재  
  - 일본 경제 특성: 잃어버린 30년, 디플레이션, 현금을 선호  
  - 일본 기업은 기존 시스템 유지에 강점, AI 기회 많음

- **사업적 접근**
  - Paid PoC 문화, 소프트웨어 성숙도 높음  
  - 기존 업무 중 AI가 잘 대체할 수 있는 부분만 선택하여 적용  

- **주요 프로젝트 사례**
  - **일본 급여 BPO AX Project**
    - 매달 160만 명 급여 처리
    - AI Agent: 허용된 테이블/컬럼만 접근, SELECT 구문 외 실행 불가  
    - 토큰 비용 고려, Solar Pro2 선택: 일본어 지원, Tool Calling, 비용 효율성, 반응 속도  
  - **일본 철도회사 AX Project**
    - 2000만 장 이상 문서 디지털화 후 DB 구축 및 AI 환경 구현
    - PDF → Markdown 변환, 다양한 OCR 라이브러리 성능 비교
    - Document Parse: 문맥과 의도를 이해, 주제별 Output 추출, 사전 훈련 불필요, 유지보수 비용 낮음
    - 범용 LLM 대비 비용·정확도·할루시네이션 고려  
    - Feedback loop로 정확도 개선

- **핵심 메시지**
  - 일본 시장은 기존 시스템 유지와 비용 효율성을 중시하는 특성 덕분에 AI 도입 기회 많음  
  - AI 프로젝트 성공을 위해 **적합한 도구 선택, 비용 관리, 정확도 확보, 단계적 적용** 중요


7. 한눈에 알아보는 LLM post-training
발표자: 조재경 | SK텔레콤 AI LLM Research
시간: 14:40 ~ 15:20
## 강의 내용
### 확장되는 LLM 생태계 : 빠르고 쉽게 확정
- LLM을 사용하는 사람들
- LLM API를 활용해 서비스를 만드는 사람들
- LLM을 만드는 사람들

### 1. LLM Post-training 개념
- LLM 지식을 사람이 유용하게 사용할 수 있도록 학습
- Pre-training: 일반 지식 학습
- Post-training: 실제 사용 목적에 맞게 지식 조정
- **SFT (Supervised Fine-Tuning)**: 긍정적 답변만 학습, 인간 선호 맞춤
- **RLHF (Reinforcement Learning with Human Feedback)**: 선호도 데이터 → Reward Model 학습 → 강화 학습
- **DPO (Direct Preference Optimization)**: 선호도 기반 학습
- **KD (Knowledge Distillation)**: 고성능 모델 지식 작은 모델로 전이

### 2. 2025년 LLM Post-training 트렌드
- 단계적 사고(think step by step) 활용 → 모델 응답 개선
- RLHF 주의점: 학습 불안정, reward hacking 가능
- RLVR: 정답 기반 강화 학습
- Reasoning + RLVR: 복잡 문제 해결 능력 향상
  - 예: 국제수학올림피아드 문제, Git 이슈 해결

### 3. 향후 방향성
- Pre-training → Post-training → Frontier 돌파
- 고품질 합성 데이터 생성 및 데이터 분포 조정
- Pre-training 세밀하게 조정 → 모델 성능 극대화

8. Document AI 서비스 성장스토리: From 1 to 100, and beyond
발표자: 문수영 | 업스테이지 SW엔지니어
시간: 15:30 ~ 16:10
## 강의 요약

### 1. 첫 번째 Document AI 제품
- 목표: 고객이 쉽게 AI를 도입할 수 있도록 하는 **간단한 MLOps 플랫폼** 구축
- 시작: 문서 AI로 방향을 잡고 집중
- 조직 문화: 재택근무였지만 합숙하듯 몰입하여 개발
- 과정: 고객 요구사항을 반영하며 모델·제품 완성도 개선
- VOC를 통해 **재사용 가능한 기능**과 **제품 코어 기능**을 선별적으로 확보

### 2. 확장성과 제품 구조에 대한 고민
- 제품이 크고 복잡해 **고객이 이해하기 어렵고**, 개발·유지보수 부담 증가
- 설치 시간도 길어지는 문제
- 베이스 모델 성능이 너무 좋아 **데이터 플라이휠(Data Flywheel)** 전략의 효과가 약화
- 실제 고객은 단순한 **추론 기능만 필요**한 경우가 많음
- 대응: **제품을 단순화**하고 핵심 추론 기능에 집중

### 3. SaaS화와 시장 검증
- 모델 추론 API만으로도 충분히 수요가 있는지 검증
- OCR Pack 서빙 파트를 독립 모듈로 분리
- 인증·과금 로직을 앞단에 붙여 빠르게 **SaaS 제품화 성공**
- 결론: 완성된 복잡한 제품을 고치기보다 **처음부터 심플하게 다시 시작하는 전략**이 효과적

### 4. 고객 반응과 엔터프라이즈 확장
- **추론 기능 집중**만으로도 고객 수가 빠르게 증가
- 하지만 엔터프라이즈 제품으로서 기능적 한계 존재
- 대응: 엔터프라이즈 고객 대응을 위한 **새로운 팀 구성**
  - 고객과 직접 맞닿으며 요구사항에 대응

### 5. 제품 딜리버리 개선
- 문제: 기존 제품 설치 과정이 복잡하고 시간이 오래 걸림
- 해결책: **솔라박스(Solar Box)** 도입  
  - 파편화된 제품들을 표준 카탈로그로 통합 관리  
  - 설치 기간을 **1주일 → 15분**으로 단축  

### 6. 향후 노력
- 글로벌 스케일 확장 준비
- 다양한 채널 확보 및 사업 다변화

9. 바이브 코딩 시대, 살아남는 개발팀의 조건
발표자: 김민혜 | 한빛앤 개발팀장
시간: 16:20 ~
## 강의 요약
### 1. 바이브 코딩 시대의 도래
- **대혼돈의 시대**
  - 지식 기반 전문성의 가치는 약화
  - AI 기술에 대한 FOMO(불안감)는 확대
- **바이브 코딩이란?**
  - AI 도움을 받아 자연어 대화로 코딩하는 방식
  - 개발자 역할은 단순히 코드 작성이 아니라  
    요구사항 분석, 아키텍처 설계, 확장성·성능·품질 보장, 지속 가능성까지 포함
- **역할 구분**
  - Programmer / Coder
  - Software Developer
  - Software Engineer (가장 확장된 역할)
- **자연어의 의미**
  - 프로그래밍 언어를 몰라도 개발 가능
  - 개발 지식 유무에 따라 요청의 구체성 차이 발생
    - 예: "로그인 기능 만들어줘" vs. 구체적 설계 기반 요청
- **Vibe Engineering**
  - LLM 원리 이해 → 더 나은 활용 가능
  - 협업 방식으로 발전시키기 위해 필요한 역량:
    - 확률적 본질 이해
    - 프롬프트 설계 능력
    - 한계 인지
    - 시스템적 이해

### 2. 개발자 업의 본질 되짚기

- **누구나 개발할 수 있는 시대, 경쟁력은?**
  - 개발자는 "기술을 통해 문제를 해결하는 사람"
  - 과정: 문제 정의 → 해결 방법 설계 → 구현 → 검증 → 개선
  - 요구사항에 맞춰 **trade-off 판단**이 중요
- **문제 정의의 중요성**
  - "아는 만큼 보인다" → 문제를 정의하지 못하면 해결도 불가능
- **개발 방법론의 변화**
  - Waterfall → Agile → AI 기반 개발 방식
- **생산성 논의**
  - 많은 기업은 신규 채용보다 기존 개발자의 생산성 증대를 요구
  - 하지만 의사결정 과정에 인간이 개입되면 병목 발생
  - 따라서 **프로세스 재편** 필요: 인간 개입 최소화

### 3. 개발자의 확장된 업무

- **Product Engineer 개념**
  - Product Manager + Fullstack Developer 역할을 아우름
  - 주요 특징:
    - AI 네이티브
    - T자형 역량
    - 성과 지향성
    - 자율적 실행력
- **개발자의 역할 확장**
  - 문제 정의자, 의사결정자, 협력자/촉진자, 검증자
  - 모든 것을 혼자 다 알 수 없으므로,  
    다양한 전문성을 가진 **T자형 Product Engineering 팀** 필요
- **핵심 메시지**
  - 결국 제품이 성공해야 개발팀도 생존
  - 안목을 넓히고, 역량을 확장하며, 팀 구조를 재편해야 한다
  - AI 시대는 **‘개인’의 능력 증강**이 아닌, **‘팀’의 성공**이 진짜 경쟁력
